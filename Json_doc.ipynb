{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6df357c",
   "metadata": {},
   "source": [
    "<div style=\"background-image: linear-gradient(to right, #4b4cff , #00d4ff); text-align: center; padding: 50px;\">\n",
    "    <h1 style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 24px; color: white; text-shadow: 2px 2px #4b4cff;\">\n",
    "        JSON to Documentation\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916094d",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #3366cc; font-family: Arial, sans-serif; font-size: 24px; font-weight: bold; text-transform: uppercase; text-align: center; border-bottom: 2px solid #3366cc; padding-bottom: 5px;\">Bibliothèque</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86fea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import re\n",
    "\n",
    "import random\n",
    "\n",
    "import json \n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from fpdf import FPDF\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb597a97",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #3366cc; font-family: Arial, sans-serif; font-size: 24px; font-weight: bold; text-transform: uppercase; text-align: center; border-bottom: 2px solid #3366cc; padding-bottom: 5px;\">doc_json</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1abb1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_json(file, sep = ',', ID = '') : \n",
    "    \"\"\"\n",
    "    Convertit un fichier CSV ou Excel en un format JSON contenant des informations statistiques sur les variables.\n",
    "\n",
    "    Args:\n",
    "        file (str): Chemin du fichier à convertir.\n",
    "        sep (str, optional): Délimiteur utilisé pour les fichiers CSV. Par défaut, ','.\n",
    "        ID (str or list, optional): Colonne(s) utilisée(s) comme identifiant(s). Par défaut, ''.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire JSON contenant les informations statistiques sur les variables du fichier.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: Si le fichier n'est pas au format CSV ou Excel.\n",
    "\n",
    "    \"\"\"\n",
    "    #--------------------------------Ouverture du fichier----------------------------------------------------------------------\n",
    "    if file.endswith('.csv'):\n",
    "        data = pd.read_csv(file, sep = sep)\n",
    "    elif file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "        data = pd.read_excel(file)\n",
    "    else:\n",
    "        return 'Erreur : Le fichier doit être au format CSV ou Excel.'\n",
    "    # Récupération du fichier\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Nom et valeurs principales du fichier-----------------------------------------------------\n",
    "    file_name = file.split('/')[-1]\n",
    "    current_date = date.today().strftime('%d-%m-%Y')\n",
    "    # Nom et date d'ouverture du fichier\n",
    "    \n",
    "    types = data.dtypes\n",
    "    columns = data.columns\n",
    "    missing_values = data.isna().sum()\n",
    "    len_data = len(data)\n",
    "    missing_values_total = data.isna().sum().sum()\n",
    "    # type des colonnes, colonnes et valeurs manquantes\n",
    "    \n",
    "    creation_timestamp = os.path.getctime(file)\n",
    "    creation_date = datetime.fromtimestamp(creation_timestamp)\n",
    "    formatted_date = creation_date.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Mise en ébauche des différentes colonnes--------------------------------------------------\n",
    "    variables = {}\n",
    "    for column, data_type in zip(columns, types):\n",
    "        variables[column] = {\n",
    "            'type': str(data_type),\n",
    "            'missing_values': int(missing_values[column])\n",
    "        }\n",
    "    # valeurs classiques (type et nombre de valeurs manquantes)\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Colonnes de types 'float/int'-------------------------------------------------------------\n",
    "    float_int_columns = types[(types == 'float64') | (types == 'int64')].index.tolist()\n",
    "    # On récupère les colonnes de types int et float\n",
    "\n",
    "    for column in float_int_columns:\n",
    "        column_data = data[column]\n",
    "\n",
    "        if len(data[column]) > 3000 : \n",
    "            sample_size = len(data[column])\n",
    "        else : \n",
    "            sample_size = 3000\n",
    "        # Taille du sample pour le test statistique\n",
    "        \n",
    "        sample = random.sample(column_data.tolist(), sample_size)\n",
    "        shapiro_stat, shapiro_pvalue = stats.shapiro(sample)\n",
    "        # Test de shapiro\n",
    "        \n",
    "        q1 = np.percentile(column_data, 25)\n",
    "        q3 = np.percentile(column_data, 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        outliers = column_data[(column_data < lower_bound) | (column_data > upper_bound)]\n",
    "        # Calcul des valeurs aberrantes\n",
    "        \n",
    "        if missing_values_total == 0 : \n",
    "            msg_val_per_tot = 0\n",
    "        else : \n",
    "            msg_val_per_tot = (int(missing_values[column]/missing_values_total))*100\n",
    "        # On fait attention car si la valeur du nombre de valeurs manquantes total est null \n",
    "        \n",
    "        variables[column] = {\n",
    "            'type': str(types[column]),\n",
    "            'statistics': {\n",
    "                'mean': np.mean(column_data),\n",
    "                'std': np.std(column_data),\n",
    "                'min': np.min(column_data),\n",
    "                'max': np.max(column_data),\n",
    "                'q1' : q1, \n",
    "                'q3' : q3,\n",
    "                'shapiro_statistic': shapiro_stat,\n",
    "                'shapiro_pvalue': shapiro_pvalue,\n",
    "                'outliers': len(outliers.tolist())\n",
    "            },\n",
    "            'missing values': int(missing_values[column]),  \n",
    "            'missing values percent column':(int(missing_values[column])/len_data) *100,\n",
    "            'missing values percent total': msg_val_per_tot\n",
    "        }\n",
    "        # On remplit le dictionnaire avec les valeurs \n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Colonne de type date----------------------------------------------------------------------\n",
    "    date_columns = [col for col, dtype in types.items() if dtype == 'datetime64[ns]']\n",
    "    # On récupère les colonnes de type date\n",
    "    \n",
    "    for column in date_columns:\n",
    "        column_data = data[column]\n",
    "        date_formats = set() \n",
    "\n",
    "        for date_value in column_data:\n",
    "            date_str = date_value.strftime('%d-%m-%Y') \n",
    "            # Conversion en chaine de caractère\n",
    "            \n",
    "            try:\n",
    "                datetime.strptime(date_str, '%d-%m-%Y')\n",
    "                date_formats.add('European')\n",
    "            except ValueError:\n",
    "                pass\n",
    "            # Format européen\n",
    "\n",
    "            try:\n",
    "                datetime.strptime(date_str, '%m-%d-%Y')\n",
    "                date_formats.add('American')\n",
    "            except ValueError:\n",
    "                pass\n",
    "            # Format américain \n",
    "            \n",
    "            if 'European' in date_formats:\n",
    "                selected_format = 'European'\n",
    "            elif 'American' in date_formats:\n",
    "                selected_format = 'American'\n",
    "            else:\n",
    "                selected_format = 'Unknown'\n",
    "            # Récupération du format\n",
    "\n",
    "        variables[column] = {\n",
    "            'type': str(types[column]),\n",
    "            'extremum': {\n",
    "                'earliest_date': np.min(column_data).strftime('%d-%m-%Y'),\n",
    "                'latest_date': np.max(column_data).strftime('%d-%m-%Y')\n",
    "            },\n",
    "            'missing values': int(missing_values[column]),\n",
    "            'date format': selected_format\n",
    "        }\n",
    "    # On remplit avec les valeurs obtenues\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Colonne de type 'année'-------------------------------------------------------------------\n",
    "    year_columns = [col for col, dtype in types.items() if dtype == 'int64' and (col.lower() == 'annee' or col.lower() == 'année' or col.lower() == 'year')]\n",
    "    # Vérifier les années dans chaque colonne\n",
    "    \n",
    "    for column in data.columns:\n",
    "        if column not in year_columns:\n",
    "            # Vérification des valeurs de la colonne\n",
    "            for value in data[column]:\n",
    "                if isinstance(value, (int, float, str)):\n",
    "                    value_str = str(value)\n",
    "                    # Conversion en chaîne de caractères\n",
    "                    if re.match(r'^\\d{4}$', value_str):\n",
    "                        # Vérification du format de l'année\n",
    "                        year = int(value_str)\n",
    "                        if 1980 <= year <= datetime.now().year:\n",
    "                            year_columns.append(column)\n",
    "                            # Vérification de la plage des années\n",
    "                            break\n",
    "\n",
    "    year_columns = list(set(year_columns))\n",
    "    # Supprimer les doublons \n",
    "    \n",
    "    for column in year_columns:\n",
    "        column_data = data[column]\n",
    "        \n",
    "        \n",
    "        variables[column] = {\n",
    "            'type': str(types[column]),\n",
    "            'extremum': {\n",
    "                'earliest_year': np.min(column_data),\n",
    "                'latest_year': np.max(column_data)\n",
    "            },\n",
    "            'missing values': int(missing_values[column])\n",
    "        }\n",
    "    # On remplit avec les valeurs extrêmes\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Colonne de type 'object'------------------------------------------------------------------\n",
    "    object_columns =  [col for col, dtype in types.items() if dtype == 'object']\n",
    "    # On récupère les colonnes de type object \n",
    "    \n",
    "    for column in object_columns: \n",
    "        column_data = data[column]\n",
    "        \n",
    "        unique = column_data.unique()\n",
    "        value_counts = column_data.value_counts(normalize=True)\n",
    "        top_values = value_counts[value_counts > 0.1]\n",
    "        top10 = top_values.index.tolist()\n",
    "        top10_percentages = (top_values * 100).round(2).tolist()\n",
    "        # On calcule les pourcentages des valeurs les plus présentes dans chaque colonne de type 'object' en affichant que celle de plus de 10%\n",
    "        \n",
    "        variables[column] = {\n",
    "            'type': str(types[column]),\n",
    "            'missing values': int(missing_values[column]), \n",
    "            '>10% appearance': dict(zip(top10, top10_percentages))\n",
    "        }\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #--------------------------------Colonne de type 'binary'------------------------------------------------------------------\n",
    "    binary_columns = []\n",
    "    # Initialisation\n",
    "    \n",
    "    for column in data.columns:\n",
    "        unique_values = data[column].dropna().unique()\n",
    "    \n",
    "        if len(unique_values) == 2:\n",
    "            binary_columns.append(column)    \n",
    "    # On écarte les valeurs manquantes et on regarde quels colonnes possède exactement deux valeurs uniques\n",
    "    \n",
    "    for column in binary_columns: \n",
    "        column_data = data[column]\n",
    "        \n",
    "        unique = column_data.unique()\n",
    "        value_counts = column_data.value_counts(normalize=True)\n",
    "        top = value_counts.index.tolist()\n",
    "        top_percentages = (value_counts * 100).round(2).tolist()\n",
    "        \n",
    "        variables[column] = {\n",
    "            'type': str('binary'),\n",
    "            'missing values': int(missing_values[column]),\n",
    "            'appearance': dict(zip(top, top_percentages))\n",
    "        }\n",
    "        # On remplit avec les pourcentages de présence de chacune des valeurs\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Colonne de type ID------------------------------------------------------------------------\n",
    "    id_columns = []\n",
    "    # Initialisation de la colonne\n",
    "    \n",
    "    for column in data.columns:\n",
    "        values = data[column].dropna()\n",
    "        values = values.astype(str)\n",
    "        # Conversion des valeurs en chaînes de caractères\n",
    "        \n",
    "        if (column not in year_columns and column not in binary_columns and column not in date_columns and len(set(map(len, values))) == 1) or ('id' in column.lower()):\n",
    "            id_columns.append(column)\n",
    "    \n",
    "    \n",
    "    for column in id_columns: \n",
    "        column_data = data[column]\n",
    "        \n",
    "        unique = column_data.unique()\n",
    "        value_counts = column_data.value_counts(normalize=True)\n",
    "        top_values = value_counts[value_counts > 0.1]\n",
    "        top10 = top_values.index.tolist()\n",
    "        top10_percentages = (top_values * 100).round(2).tolist()\n",
    "        \n",
    "        unique_values = len(column_data.value_counts())\n",
    "        highest_app = max(column_data.value_counts())\n",
    "        nbr_hgh_app = sum(column_data.value_counts() == highest_app)\n",
    "        # Valeurs à ajouter dans les variables identifiants\n",
    "        \n",
    "        variables[column] = {\n",
    "            'type': str('Identifiant'),\n",
    "            'missing values': int(missing_values[column]), \n",
    "            'unique value': unique_values,\n",
    "            'highest appearance': highest_app,\n",
    "            'nbr of highest app': nbr_hgh_app,\n",
    "            '>10% appearance': dict(zip(top10, top10_percentages))\n",
    "        }                \n",
    "        # On remplit avec les pourcentages de présence de chacune des valeurs\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Colonne de type ID------------------------------------------------------------------------\n",
    "    try:\n",
    "    # On teste si ID n'est pas vide\n",
    "        if ID:\n",
    "            id_colonne = data[ID]\n",
    "\n",
    "            unique_values = len(id_colonne.value_counts())\n",
    "            highest_app = max(id_colonne.value_counts())\n",
    "            nbr_hgh_app = sum(id_colonne.value_counts() == highest_app)\n",
    "            # valeur unique et nombre d'apparitions\n",
    "\n",
    "            unique = id_colonne.unique()\n",
    "            value_counts = id_colonne.value_counts(normalize=True)\n",
    "            top_values = value_counts[value_counts > 0.1]\n",
    "            top10 = top_values.index.tolist()\n",
    "            top10_percentages = (top_values * 100).round(2).tolist()\n",
    "            # Valeur avec le plus de présence et son pourcentage\n",
    "\n",
    "            variables[ID] = {\n",
    "                'type': str('ID'),\n",
    "                'missing values': int(missing_values[ID]),\n",
    "                'unique value': unique_values,\n",
    "                'highest appearance': highest_app,\n",
    "                'nbr of highest app': nbr_hgh_app,\n",
    "                '>10% appearance': dict(zip(top10, top10_percentages))\n",
    "                }\n",
    "    except KeyError:\n",
    "        pass\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #--------------------------------Mise en forme des résultats---------------------------------------------------------------\n",
    "    json_resultat = {\n",
    "        'file_properties': {\n",
    "            'file_name': file_name,\n",
    "            'date': current_date,\n",
    "            'Nombre de lignes' : len_data,\n",
    "            'Missing values' : missing_values_total,\n",
    "            'Date de création' : formatted_date\n",
    "        },\n",
    "        'variables': variables\n",
    "    }\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    return json_resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb25c8d",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #3366cc; font-family: Arial, sans-serif; font-size: 24px; font-weight: bold; text-transform: uppercase; text-align: center; border-bottom: 2px solid #3366cc; padding-bottom: 5px;\">Mise en page</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2908a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json(json_data):\n",
    "    \"\"\"\n",
    "    Formate le contenu JSON pour une meilleure lisibilité.\n",
    "\n",
    "    Arguments :\n",
    "    - json_data : dict : Les données JSON à formater.\n",
    "\n",
    "    Retourne :\n",
    "    - str : Le contenu JSON formaté.\n",
    "    \"\"\"\n",
    "    indent = 4 \n",
    "    sorted_json = json.dumps(json_data, indent=indent, sort_keys=True, ensure_ascii=False, default=convert_to_builtin_type)\n",
    "    formatted_json = \"\"\n",
    "\n",
    "    level = 0\n",
    "    for char in sorted_json:\n",
    "        if char == '{':\n",
    "            formatted_json += char + \"\\n\" + \" \" * (indent * (level + 1))\n",
    "            level += 1\n",
    "        elif char == '}':\n",
    "            formatted_json += \"\\n\" + \" \" * (indent * (level - 1)) + char\n",
    "            level -= 1\n",
    "        elif char == ',':\n",
    "            formatted_json += char + \"\\n\" + \" \" * (indent * level)\n",
    "        else:\n",
    "            formatted_json += char\n",
    "\n",
    "    return formatted_json\n",
    "\n",
    "def convert_to_builtin_type(obj):\n",
    "    \"\"\"\n",
    "    Convertit les types d'objets personnalisés en types JSON sérialisables.\n",
    "\n",
    "    Arguments :\n",
    "    - obj : object : L'objet à convertir.\n",
    "\n",
    "    Retourne :\n",
    "    - object : L'objet converti.\n",
    "\n",
    "    Raises :\n",
    "    - TypeError : Si l'objet n'est pas sérialisable en JSON.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, np.int64):\n",
    "        return int(obj)\n",
    "    raise TypeError(\"Object of type '{}' is not JSON serializable\".format(type(obj).__name__))\n",
    "\n",
    "#result = doc_json('./data/fr-en-ips_colleges.csv', ';')\n",
    "#formatted_json = format_json(result)\n",
    "#print(formatted_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b9b6e",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #3366cc; font-family: Arial, sans-serif; font-size: 24px; font-weight: bold; text-transform: uppercase; text-align: center; border-bottom: 2px solid #3366cc; padding-bottom: 5px;\">Mise en page PDF</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "195a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDF(FPDF):\n",
    "    \"\"\"\n",
    "    Classe PDF étendue pour la création de fichiers PDF personnalisés.\n",
    "\n",
    "    Cette classe hérite de la classe FPDF du module fpdf.\n",
    "\n",
    "    Méthodes spéciales :\n",
    "    - header() : Définit le contenu de l'en-tête du document PDF.\n",
    "    - footer() : Définit le contenu du pied de page du document PDF.\n",
    "\n",
    "    Méthodes personnalisées :\n",
    "    - chapter_title(title) : Ajoute un titre de chapitre au document PDF.\n",
    "    - chapter_body(content) : Ajoute le contenu d'un chapitre au document PDF.\n",
    "    \"\"\"\n",
    "    \n",
    "    def header(self):\n",
    "        \"\"\"\n",
    "        Définit le contenu de l'en-tête du document PDF.\n",
    "        \"\"\"\n",
    "        self.set_font('Arial', 'B', 14)\n",
    "        self.cell(0, 10, 'Documentation de CSV/XLSX', align='C')\n",
    "        self.ln(15)\n",
    "\n",
    "    def footer(self):\n",
    "        \"\"\"\n",
    "        Définit le contenu du pied de page du document PDF.\n",
    "        \"\"\"\n",
    "        self.set_y(-15)\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        \"\"\"\n",
    "        Ajoute un titre de chapitre au document PDF.\n",
    "\n",
    "        Arguments :\n",
    "        - title : str : Le titre du chapitre.\n",
    "        \"\"\"\n",
    "        self.set_font('Arial', 'B', 20)\n",
    "        self.cell(0, 10, title, ln=True)\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_body(self, content):\n",
    "        \"\"\"\n",
    "        Ajoute le contenu d'un chapitre au document PDF.\n",
    "\n",
    "        Arguments :\n",
    "        - content : str : Le contenu du chapitre.\n",
    "        \"\"\"\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, content)\n",
    "        self.ln(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32947e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_from_json(json_data, output_file, file_name):\n",
    "    \"\"\"\n",
    "    Crée un fichier PDF à partir des données JSON fournies.\n",
    "\n",
    "    Arguments :\n",
    "    - json_data : str : Les données JSON au format texte.\n",
    "    - output_file : str : Le nom du fichier PDF de sortie.\n",
    "    - file_name : str : Le nom du fichier d'origine.\n",
    "\n",
    "    Cette fonction crée un fichier PDF à partir des données JSON fournies.\n",
    "    \n",
    "    Returns:\n",
    "        .pdf: un pdf contenant les informations du json.\n",
    "    \"\"\"\n",
    "    data = json_data    \n",
    "    pdf = PDF()\n",
    "    pdf.add_page()\n",
    "    # Initialisation\n",
    "    \n",
    "    pdf.set_font('Arial', 'B', 24)  \n",
    "    pdf.cell(0, 10, file_name, ln=True, align=\"C\", border=1, fill=False)\n",
    "    # Titre\n",
    "    \n",
    "    pdf.ln(10)\n",
    "    # Saut de ligne\n",
    "    \n",
    "    pdf.chapter_title(\"File_properties\")\n",
    "    pdf.chapter_body(str(data['file_properties']))\n",
    "    # Titre de chapitre\n",
    "\n",
    "    pdf.ln(10)  \n",
    "    # Saut de ligne\n",
    "    \n",
    "    pdf.chapter_title(\"Variables\")\n",
    "    # Titre de chapitre\n",
    "    \n",
    "    for key, value in data['variables'].items():\n",
    "        pdf.chapter_body(f\"{key}: {value}\")\n",
    "        pdf.ln(5)  # Saut de ligne entre les valeurs\n",
    "    # Ajouter chaque paire clé-valeur avec un saut de ligne\n",
    "    \n",
    "    pdf.output(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8caa207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m{\u001b[39;00mfile_name\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     22\u001b[0m         json\u001b[39m.\u001b[39mdump(result, file, sort_keys\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, ensure_ascii\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, default\u001b[39m=\u001b[39mconvert_to_builtin_type)\n\u001b[0;32m---> 24\u001b[0m main(\u001b[39m'\u001b[39;49m\u001b[39m./data/house_price.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(file, sep)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mMet en application les différentes fonctions établis précédemment. Et renvoie un fichier json du fichier passé en argument.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mOn peut aussi préciser le séparateur dans le cas ou = ;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m    .json : un dictionnaire json contenant les informations du fichier.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m file_name \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m result \u001b[39m=\u001b[39m doc_json(file, sep)\n\u001b[1;32m     18\u001b[0m output_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./documentationPDF/\u001b[39m\u001b[39m{\u001b[39;00mfile_name\u001b[39m}\u001b[39;00m\u001b[39m.pdf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m create_pdf_from_json(result, output_file, file_name)\n",
      "Cell \u001b[0;32mIn[17], line 70\u001b[0m, in \u001b[0;36mdoc_json\u001b[0;34m(file, sep, ID)\u001b[0m\n\u001b[1;32m     67\u001b[0m     sample_size \u001b[39m=\u001b[39m \u001b[39m3000\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39m# Taille du sample pour le test statistique\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m sample \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49msample(column_data\u001b[39m.\u001b[39;49mtolist(), sample_size)\n\u001b[1;32m     71\u001b[0m shapiro_stat, shapiro_pvalue \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39mshapiro(sample)\n\u001b[1;32m     72\u001b[0m \u001b[39m# Test de shapiro\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/random.py:482\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    480\u001b[0m randbelow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_randbelow\n\u001b[1;32m    481\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m k \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n:\n\u001b[0;32m--> 482\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSample larger than population or is negative\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    483\u001b[0m result \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m k\n\u001b[1;32m    484\u001b[0m setsize \u001b[39m=\u001b[39m \u001b[39m21\u001b[39m        \u001b[39m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "def main(file, sep = ',') : \n",
    "    \"\"\"\n",
    "    Met en application les différentes fonctions établis précédemment. Et renvoie un fichier json du fichier passé en argument.\n",
    "    On peut aussi préciser le séparateur dans le cas ou = ;\n",
    "\n",
    "    Arguments :\n",
    "    - file : chemin vers le fichier .csv/.xlsx.\n",
    "    - sep : le séparateur utilisé dans le fichier, par défaut ','.\n",
    "\n",
    "    Cette fonction crée un dictionnaire json à partir du fichier donné en argument.\n",
    "    \n",
    "    Returns:\n",
    "        .json : un dictionnaire json contenant les informations du fichier.\n",
    "    \"\"\"\n",
    "    file_name = file.split('/')[-1]\n",
    "    result = doc_json(file, sep)\n",
    "    \n",
    "    output_file = f\"./doc file/{file_name}.pdf\"\n",
    "    create_pdf_from_json(result, output_file, file_name)\n",
    "    \n",
    "    with open(f'./data/{file_name}.json', 'w') as file:\n",
    "        json.dump(result, file, sort_keys=True, ensure_ascii=False, default=convert_to_builtin_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
